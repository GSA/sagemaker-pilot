{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the labeled documents\n",
    "This notebook assumes:\n",
    " - You've got all of the labeled solicitaton documents within a directory named `labeled_fbo_docs`\n",
    " - You can use the awscli to push a csv up to an S3 bucket named (our is named `srt-sm`).\n",
    "\n",
    "Below, we'll read in each document and extract the text along with the label (the label is in the file name). Although there are three lables (red, yellow and green), we're combining red and yellow as noncompliant ($0$) and treating green as compliant ($1$). This makes our binary classification challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data = []\n",
    "for file in os.listdir('labeled_fbo_docs'):\n",
    "    if file.startswith('GREEN'):\n",
    "        target = 1\n",
    "    elif file.startswith('RED') or file.startswith('YELLOW'):\n",
    "        target = 0\n",
    "    else:\n",
    "        raise Exception(f\"A file isn't prepended with the target:  {file}\")\n",
    "    \n",
    "    file_path = os.path.join(os.getcwd(), 'labeled_fbo_docs', file)\n",
    "    with open(file_path, 'r', errors = 'ignore') as f:\n",
    "        #do some newline replacing\n",
    "        text = f.read().replace(\"\\n\", ' ').strip()\n",
    "    data.append([target, text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the training data to csv\n",
    "Here we'll write this training data to a single csv, with the headers `target` and `text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('srt_train.csv', mode='w') as f:\n",
    "    csvwriter = csv.writer(f, delimiter=',')\n",
    "    csvwriter.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push training data to S3\n",
    "You'll need to have installed the awscli prior to this step and have configured it to use the Key ID and Secret Access Key of your AWS account. You can do that with the `aws configure` as documented [here](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html#cli-quick-configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing to s3n://srt-sm/training/srt_train.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "region = boto3.Session().region_name\n",
    "bucket = 'srt-sm' \n",
    "prefix = 'training' # Used as part of the path in the bucket where we'll store train and test data\n",
    "bucket_path = f'https://s3-{region}.amazonaws.com/{bucket}'\n",
    "\n",
    "upload_file = 'srt_train.csv'\n",
    "key = f'{prefix}/{upload_file}'\n",
    "s3.Bucket(bucket).Object(key).upload_file(upload_file)\n",
    "url = f's3n://{bucket}/{key}'\n",
    "print(f'Done writing to {url}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokenization",
   "language": "python",
   "name": "tokenization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
